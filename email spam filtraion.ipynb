# import necessary liabrabies
import pandas as pd
from sklearn import metrics
import pandas as pd
from sklearn import metrics

#load the news datasets

df=pd.read_csv("spam.csv")
total=df.groupby('Category').describe()
print(total)

#data preprocessing we drop the unwanted columns that didn`t used for predictions
#create a new column name spam ehere emails have labeled as:
#label: spam=1 otherwise 0
df['spam']=df['Category'].apply(lambda x:1 if x=='spam'else 0)
df=df.drop("Category",axis="columns")
print("\nprocessed data set:\n")
print("\n",df.head())

      
#now splitting the dataset into input and target sets
input=df.Message
target=df.spam

#dividing the dataset into training and testing sets
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(input,target,test_size=.2) #20% of the datasets is used into test case

#using count vectorizer we generate the tokens and their frequency distrybution (occurance)
from sklearn.feature_extraction.text import CountVectorizer
v=CountVectorizer()
x_train_count=v.fit_transform(x_train.values)
x_train_count.toarray()#convert the tokens into array
x_test_count=v.transform(x_test.values)
x_test_count.toarray()
      
#implement the classifier
from sklearn.naive_bayes import MultinomialNB
clf=MultinomialNB()
clf.fit(x_train_count,y_train)
pred1=clf.predict(x_test_count)
score=clf.score(x_test_count,y_test)
print("\npredictions:\n",pred1)
print("\nModel Score is: ",score)
      
#for further validation
emails=['hey sahil is your sirname is really Raj!',
       'click here to get 50% discount',
       'study abroad vissa hurry in 5 minutes']
emails_count=v.transform(emails)

pred=clf.predict(emails_count)
print("\n For Validation Email Set:\n")
print("output(1:spam/0:ham)  : ",pred)
